# 介绍篇
## 1. 自我介绍
面试官您好，我是古心竹，目前在北京航空航天大学读研二，预计2027年毕业，目前主要是希望在咱们公司找一份日常实习，可以实习到明年的六七月份左右
然后我目前

## 2. 项目介绍
（心理咨询小程序是两个人一起完成的，你负责后端，不负责前端）
这个心理咨询小程序是B/S架构的程序，我主要负责开发后端部分，大体介绍一下的话
后端我使用Java基于SpringBoot开发，使用MySQL作为数据库，使用Redis作为缓存提升性能，使用RabbitMQ实现异步通信，解耦了网关模块和业务处理模块，然后实现了用户和咨询师的登录、咨询课程发布、以及核心的预约咨询等功能
在这个项目中，自己觉得做的比较好一些的部分，主要是为核心的预约业务，做了很多工作来保证它的高可用和高并发能力

### 2.1 你这个项目是什么背景，有多少流量，具体你做了什么
是和组里另一个人一起做的项目，是边学习边开发想用来参加微信小程序设计比赛，目前没有发布到给真实客户使用，主要是自己测试。我负责了后端所有内容的搭建

# 登录篇
## 0. 说一下你怎么设计实现的用户身份认证
在项目中我基于JWT设置了用户的身份认证逻辑，具体是当用户进行登录时，程序中的网关模块进行密码校验，如果校验通过则在服务端生成一个JWT token，将这个token返回给
前端，此后前端每次发起其他业务请求都会携带这个token；服务端在controller层使用spring mvc来注册全局拦截器，在收到http请求后首先拦截进行前置处理，进行JWT token的合法性校验，如果校验通过
再真正进入到业务处理逻辑。

### 0.1 具体说说客户端请求的token放在请求的哪里？
JWT的token放在HTTP的请求头里面传递，参数的key叫Authorization，然后value中存放token

### 0.2 你具体在注册拦截器验证token的时候是怎么做的
因为我的项目是基于Spring的，所以直接使用了Spring MVC提供的WebMvcConfigurer，具体是新建了一个类实现了WebMvcConfigurer接口，实现了addInterceptors方法，这个方法
就是Spring MVC指定用于实现全局拦截器的方法。在addInterceptors中注册了一个自定义的HandlerInterceptor，实现了里面的preHandle方法，这个方法是Spring MVC
拦截器链中的前置处理方法，在控制器方法执行前调用，所以可以在这里实现jwt的token验证，具体验证时重新使用token的header和payload加密钥计算生成signature，如果和客户端传来
的一致就判定通过。

## 1.你在设计登录时使用了JWT机制，什么是JWT
JWT是JSON Web Token，是一种标准，通常用于身份验证和信息交换。当用户进行登录时，服务端生成一个JWT token，将这个token返回给用户，此后用户每次请求都会携带JWT token，服务端会根据客户token中的header和payload计算signature，计算后和客户传来的比对，校验token签名，
如果是一致的说明token是服务端签发的，没有过期的话就认为用户还处于登录状态，从而实现服务端无状态的登录。

具体而言，JWT由三部分组成，分别是Header头部、Payload载荷、Signature签名，Header和Payload都是json格式数据进行base64编码得到，Signature是前两者的组合，经过服务器秘钥和算法的加密计算得到。
Header中主要存放使用哪种算法加密，以及声明token类型是JWT；
Payload中主要存放用户相关信息，如用户名id等

## 2.你在JWT中是怎么区分哪个用户的
解析Payload后查看用户信息即可


## 3.为什么要用JWT，有什么好处，不能直接用sessionId吗
JWT不需要服务器存储状态，只需要服务器存储一把秘钥，相对传统有状态的sessionID存储会方便很多，不需要每次查询比对token，因此节省了数据查询的io时间，适应分布式架构，不存在分布式系统token管理的问题；JWT可以扩展和定制，灵活性高

## 4.如何实现用户注销登录
如果是过期注销，可以使用内置的过期时间机制自动失效，确保token不是永久有效的，在payload中设置exp时间戳就可以了，这样服务器每次验证token时都会检查是否超时。

如果是用户主动注销，比较简单的做法是依赖前端，当客户注销登录时，前端把本地存储的JWT token删除，这样后续请求中就不会携带令牌，无法访问资源。如果追求更安全的方案，服务器可以维护一个token黑名单，如果用户发起注销则将token放入黑名单中，验证token时首先进行黑名单校验。黑名单后续等token过期或者用户重新登录时删除即可。

## 5.你在数据库中怎么存储的密码
采用了MD5加密算法处理后进行的存储，防止密码明文存储易泄露

## 6.为什么用MD5加密，一定不会泄露吗
因为MD5算法是一种哈希算法，计算过程是不可逆的，生成散列值后就无法再还原得到原文。后续通过比对散列值来验证用户名密码，就不用担心密码泄露了。

目前并不是绝对安全的，之前MD5已经被破解，如果服务器被劫持还是有泄露风险，如果从加密的角度考虑，也可以替换为更安全的argon2等算法，核心思路都是一样的。同时也可以对登录增加双因素验证等方式加固，防止密文泄露也是比较关键的。

## 7.JWT中的数据为什么要用base64编码？
主要是方便传输，因为jwt使用http协议传输，服务器和浏览器解码可能会受一些特殊字符的影响，在把内容转换为base64编码时会替换为安全字符，可以避免因为特殊符号等格式解析问题带来的编解码错误，增强兼容性。同时这种编码是无损的，保证了数据的完整性

## 8.你在JWT中用的什么签名算法，是对称的还是非对称的，有什么区别？
项目中用到的是对称加密算法，HS256
对称算法使用同一把密钥进行加密和解密；而非对称算法使用一对互补的公钥和私钥，公钥加密私钥解，或者私钥加密公钥解；
对称算法速度快但密钥分发风险大，在分布式环境中，任何一个节点拿到私钥就可以用来签发token，
非对称算法用私钥签名，用公钥验，可以把私钥保存在单一的节点，其他节点只用公钥验证，安全性很高，但计算相对较慢

## 9.MAC 摘要算法是什么
MAC（Message Authentication Code 消息认证码）是一种带密钥的哈希函数，它通过将 密钥 与 消息 共同运算生成一个签名，用于验证数据的完整性，（确保没被改过）和真实性（确保是密钥持有者发的）。
与普通哈希（如 MD5）不同，黑客由于没有密钥，即便截获并篡改了消息，也无法伪造出匹配的 MAC 标签，从而在 HTTPS 和接口签名等场景中有效杜绝了中间人篡改
JWT的签名就属于MAC的应用

// TODO: 解决击穿和穿透
# 架构篇
## 1.你在项目中怎么设计使用缓存的，怎么使用redis的
在项目中，我主要采用 Redis 作为旁路缓存（Cache-Aside）来减轻 MySQL 的查询压力。
具体设计上，我将高频访问的咨询师课程对象序列化为 JSON 字符串存入 Redis
并为 key 设置了随机扰动的过期时间以防缓存雪崩；
为了保证数据一致性，我采用了先更新数据库，再删除缓存的策略，并结合 Canal 监听 Binlog 实现了异步延迟双删，从而确保了系统在高并发场景下的最终一致性

### 1.1 如果先删缓存，再更新数据库行不行？
先删缓存的话很可能发生存在脏数据的问题，因为在并发下，如果读请求和写请求同时到来，在写请求删完缓存后但更新完数据库之前，读请求此时可能将旧数据重新载入缓存，
这会造成长时间的脏数据。

### 1.2 先更新数据库再删缓存就没问题了吗？
先更新数据库再删缓存大概率没问题，但是如果缓存刚好失效，且读写请求并发时，可能出问题，
比如读请求在未查询到缓存时，会从数据库查到原始数据试图写回redis，然后写请求稍微晚一点到来，修改了数据库，试图删除缓存。
如果读请求写回redis时发生了延迟，导致写请求先删了缓存，随后读请求完成缓存写回，导致旧数据覆盖了新数据
但是通常读请求快于写请求，所以一般不会发生

// TODO: check
### 1.3 那怎么彻底缓存解决脏数据问题/有没有其他方法解决
简单一点的话，可以采取延迟双删的策略，写请求在结束后延迟一会儿再重复删一次，确保能把意外产生的脏数据清理掉，但是就会造成下次读请求的查库
更好的做法是，我会配合 Canal 监听 Binlog 异步删除，确保系统的最终一致性 

### 1.4 你缓存架构中的具体实现
我通过Spring Cache的一些注解实现的旁路缓存，
读请求是用@Cacheable注解注册在数据库的查询方法上面，spring会自动帮忙先查缓存，如果缓存没有命中从数据库中查，查到后会自动写到缓存中
写请求是用@CacheEvict注解注册在数据库的写入方法上面，spring会写完库后自动删一次缓存
所以写请求第一次删除是spring cache帮我做的，第二次则是我使用redis template手动又删了一次
解决缓存穿透是在spring cache中做了配置，设置了allowCacheNullValues，允许缓存设置空值，这些配置的过期时间比较短

#### 1.4.1 spring cache是什么，说一说
Spring Cache是Spring提供的一个针对缓存的框架。
它本身不是一种具体的缓存的具体实现，而是通过定义了一些注解，能以很简单的方式给代码增加常用的缓存功能

#### 1.4.2 有哪些注解？
@Cacheable	用在查询时，先查缓存，没有再查数据库并存入缓存
@CacheEvict	用在更新或者删除时，数据更新了，把对应的旧缓存删掉
@CachePut	不论如何都执行方法，并把结果同步到缓存

### 1.5 怎么解决缓存穿透的
查询到不存在的数据时，把redis中也设置一个null值，从而避免下次查询走数据库；
但是这样存在问题，如果有恶意攻击大量请求不存在的key值，会导致redis中设置大量null值
因此可以在从redis中查询数据前，使用布隆过滤器判断key是否存在，如果不存在则直接拒绝请求，避免给redis过多压力

### 1.6 什么是布隆过滤器
布隆过滤器是一种空间效率很高的概率型数据结构，它利用一个很长的二进制向量（位数组）和多个哈希函数来快速判断一个元素是否在集合中：
其特点是如果判定元素不存在则一定准确，但判定元素存在时则可能发生误判（由于哈希冲突导致）

布隆过滤器的工作原理是利用一个长度为M的位数组和K个相互独立的哈希函数：
当存入一个元素时，分别用这K个哈希函数计算出K个位置并将数组中对应的位设为1
当查询一个元素时，只要有任意一位为0那说明该元素一定不存在,
只有这K个位置全部为1才判定该元素可能存在，当然因为哈希碰撞的问题所以不能说一定存在，只是可能存在
这种机制通过牺牲极小的误判率换取了极高的空间利用率和查询性能。

### 1.7 你为什么要用rabbitmq
因为它基于AMQP协议，数据可靠性非常高，有确认机制保证消息不丢失，符合我的业务场景
它因为有交换机的概念，把生产者和队列解耦了，所以路由逻辑很灵活，消息业务分发很灵活；
同时它延迟也很低，只有微秒级，完全满足我的使用

## 1. 你在程序中是如何实现提升性能和高并发的
首先为了优化了程序中各种数据库查询IO操作，做了旁路缓存，最常用的数据例如用户信息、咨询师信息等加载在程序内存中；可能被时常访问到的数据加载在redis缓存中，例如各咨询师可用时间信息、位置信息、已经预约信息等；其他查询不频繁的数据放在数据
库中，不加进缓存，例如历史评分记录、历史咨询记录等。
其次我使用rabbitmq解耦了网关模块和业务处理模块，消息可以异步的处理，业务模块根据自己消费能力处理事务，不会被打垮
我也增加了限流算法保证系统的稳定性
同时我做了一些JVM调优，优化了延迟卡顿

### 1.1 为什么要异步下单？
这样客户的请求发到网关后，只需要给业务模块发完MQ就能返回响应，请求处理速度特别快，不会卡住导致大量请求在响应，耗尽系统资源。
可以提高系统处理用户请求的吞吐量，让耗时的部分自己慢慢执行

### 1.2 那如果业务模块里的消息失败了怎么办
这样就把用户的这条预约请求记录的状态设置为失败，前端轮询查看到失败时，用户就知道失败了

### 1.3 怎么解决热key问题，redis要是扛不住怎么办？
可以对请求进行多级分流：
比如做两级缓存，将热点数据缓存到本地内存中，请求进来查到内存就返回，进不到redis，
同时也可以搭建redis集群做多个节点，把redis的Key打散后，分发到不同节点来分散单节点的压力

# AOP篇
## 1. 你在项目中是怎么使用AOP编程的
用AOP主要面向那些散布在各处，但是与那些具体业务功能无关的公共功能，在我的项目中的一个典型应用就是业务接口的流量限速，有些业务接口需要限制流量，因此通过对业务接口切面添加前置通知，在具体业务执行前
进行限速验证，通过后再进入正常业务逻辑

具体来说，我编写了一个自定义注解RateLimit，设置注解的生命周期是runtime等级，target设置为method，然后把限速用到的关键配置项，写为注解的成员变量。当使用注解时，将该注解注册在目标方法上，
并配置好限速参数。然后我通过aspect注解编写了一个切面类，设置切点为我的自定义注解注册到的所有方法（具体是在around注解中定义了annotation），使用环绕通知Around的方式，获取到切点信息ProceedingJoinPoint，
这里我需要的就是从ProceedingJoinPoint中获取MethodSignature中获取方法名，以及通过ProceedingJoinPoint的getArgs获取原本方法的入参，得到用户id，然后组合起来作为我的限速key，完成限速逻辑校验。通过后再
执行业务方法。


# MQ篇

## 1. 你在项目中怎么使用的rabbitmq
我在项目中使用RabbitMQ实现预约申请的异步通知功能，降低了网关模块与预约处理模块的耦合，
我的具体工作包括：
首先设计消息模型：设计了发起预约、预约成功等事件的消息定义；(json)
然后通过依赖Spring Boot amqp，使用RabbitTemplate编写生产者，把消息发送给指定交换机，
MQ的交换机会根据routing key进行正则表达匹配，路由到队列中，
最后使用RabbitListener注解来编写消费者，获取MQ中的消息并进行处理
同时也确保了消息不丢失，和不重复消费

## 2. 消息队列处理订单，如果消息丢失怎么办
在rabbitmq中 ，主要通过消息确认机制确保消息的达到能够被感知到，而未确认的异常消息超时将放到死信队列中等待处理，不会被丢弃
具体来说首先开启发送方确认（Publisher Confirm）确保消息到达交换机，并配合回退模式（Return）防止路由失败；
最后关闭接收方的自动 ACK，改为手动确认（Manual ACK），确保业务逻辑执行成功后再给MQ confirm。
最后，将交换机、队列及消息全部设为持久化（Durable & Persistent），防止磁盘数据丢失；

## 2.1 回退模式是什么
如果因为MQ配置错误导致 Routing Key 匹配不到队列，如果不开启MQ的回退模式，消息会丢失。
所以需要配合 Return 模式，将 mandatory 参数设为 true。这样一旦发生路由失败，MQ 就会把消息退回给我的 Spring Boot 程序，触发 ReturnCallback，避免消息丢失在交换机中
## 3. 消息队列处理订单，怎么确保消息不被重复消费的
在项目中，涉及非幂等操作的业务接口，我在网关就为发送到mq中的消息增加了一个request id，这个id是全局唯一的，在消费者进行消息消费时，需要检查request id是否
已经处理过，如果已经处理过则拒绝这次请求

# 分布式篇

## 1. 说说你是怎么生成的request id？
我通过使用snowflake来生成id，用snowflake可以在分布式的环境下保证生成全局唯一的requestId, 
这个ID是一个64位的整数，其中包括41位的毫秒级时间戳、10位的机器ID，因为有10位所以最多可以区分2的十次方，也就是1024台机器的id
还有12位的序列号，是指一个毫秒内能产生的序号。
通过这三部分，它保证了同一台机器在不同时间生成的序列号一定不同，然后通过机器码保证了不同机器生成的ID一定不同，从而是全局唯一的

然后就是在spring mvc的controller拦截器中，生成这个id，并且设置在这个线程的threadlocal中，
然后在拦截器的afterCompletion中，清除这个值

### 1.1 为什么要在afterCompletion中清除这个值？
因为Web容器中是用线程池处理http请求的，threadlocal中的值是线程私有的，
如果不手动remove，当一个线程被复用时可能会读到旧数据，不过在登录id可能大概率没问题，因为正常情况下会覆盖掉这个值

再就是因为要防止内存泄漏，因为ThreadLocal底层是ThreadLocalMap，其中Key是弱引用，Value是强引用，
在拦截器没销毁之前，会持有对这个key的强引用，从而不会被GC回收，当拦截器销毁后，key变成只有弱引用而被下次GC回收
但是Value此时还被ThreadLocalMap强引用着，从此以后既不使用也无法被GC掉
所以必须在finally块中清除数据


# 限速篇
我在项目中实现了基于多层滑动窗口和令牌桶算法的分布式限速系统，支持动态调整策略

## 1. 为什么要限速，简单介绍一下你限速的实现方式
一个是保护系统稳定性，防止因突发大流量导致服务器资源耗尽
再就是对于核心的业务接口，例如预约功能，如果不做限速，客户端可以通过脚本可以在短时间内发出大量请求，严重破坏预约的公平性；
同时对于AI咨询，由于需要严格控制下游token的消耗，所以
需要对此类接口进行限速控制。
因此我设计了一个双层分布式限速系统，主要实现了用户级限速和业务级限速：
例如在预约接口上面
、主要精确控制单位时间内的请求次数，例如预约接口限速我们是每个用户每秒一次，AI咨询是每小时120次
业务级通过令牌桶实现限流，主要用来平滑流量，因为滑动窗口不太能平滑流量的分布，所以是用了令牌桶来平滑那种瞬时的流量（例如预约接口令牌生成速率是500/秒，桶容量是800）


### 1.2 什么是令牌桶限速，介绍一下
令牌桶算法的是，建立一个用来装令牌的桶，系统以固定速率向桶中投放令牌，桶有最大容量，当桶满时新生成的令牌会被丢弃。
每当到来http请求时，需消耗一个令牌才能被继续处理。
如果桶中有足够令牌，请求立即被处理；没有的话，就看作是超速拒绝，提示用户请求过于频繁。
这种算法允许一定的突发流量，因为桶中积累的令牌可以一次性被消耗掉，同时也因为桶容量有限，所以可以平滑流量，流量不会一直很大

### 1.3 什么是滑动窗口限速，介绍一下
滑动窗口算法是设置一个时间窗口，动态地统计最近一个时间窗口内的请求数量，设置一个最大请求数的阈值
当新请求到达时，算法会检查最近一个时间窗口内的请求总数是否超过阈值。
超过则说明超速需要拒绝请求，没有超过则正常处理请求，并将此次请求记录下来

这种设计提供了更精确的限流控制，避免了固定窗口算法在窗口边界可能出现的双倍流量问题

### 1.4 具体怎么实现滑动窗口限速的
我在项目中基于Redis，在lua脚本中编写实现了滑动窗口算法，用Redis的有序集合（ZSET）实现了滑动窗口限流。
具体来说，需要把请求对应的userId当作key，（当然userId前面加个滑动限速的命名空间）
然后zset里面score是请求到来时对应的时间戳，member是请求id，再设置窗口内最大请求数量阈值
当一个请求到来时，先滑动窗口，通过当前时间戳减去窗口时间，算出过期的时间点，然后通过ZREMRANGEBYSCORE 移除这个时间点之前的数据
再用ZCARD统计当前窗口内的请求数，如果没有超过计数就插入新请求对应的时间戳，大于等于阈值则认为超速拒绝
整个过程封装在Lua脚本中保证原子性。


### 1.5 为什么用redis和lua脚本
使用redis可以天然的完成分布式限速，所有服务器都需要访问redis维护同一份限速数据，而使用lua脚本是为了保证上述操作的原子性，消除了条件，避免并发
安全问题，比如两个请求同时到来，同时看到未超速，结果瞬间通过了两次请求，就会超速，而redis是单线程模型，lua脚本在redis中
是单线程执行的，因此避免了这个安全问题

### 1.6 你的令牌桶限速是自己写的吗，介绍一下
是的，其实也可以使用guava库的令牌桶

### 1.7 你的令牌桶怎么保证线程安全的
为了提高限流效率使用了无锁方案，线程安全是通过concurrentHashmap的compareAndSet保证的，compareAndSet会使用操作系统的CAS机制
（如 x86 的 CMPXCHG），在单个指令周期内完成比较和交换，不会被线程调度打断，保证令牌桶检查数值和设置数值的原子性，从而避免了竞态条件

## 2. 什么是lua脚本，为什么在redis中使用它
Lua是一种轻量级的脚本语言，Redis内置了Lua解释器。在Redis中使用Lua脚本主要是为了：
保证一系列操作的原子性：多个Redis命令组合执行，不会被其他命令打断，在保证原子性后可以避免一些并发安全问题
同时也减少网络开销、提升性能：多个操作一次发送，减少网络往返，脚本在服务端执行，比客户端多次调用更快

在限流场景中，我用Lua脚本实现了滑动窗口算法，保证了计数器读取-判断-写入的原子性，防止并发时数据出错

## 3. 既然你已经用了滑动窗口，为什么还要再用令牌桶限速
主要是应用情景不同，核心功能对用户级别的限速我主要使用了滑动窗口，例如预约接口限速我们是每个用户每秒一次，AI咨询是每小时120次来控制风险
然后业务系统级别的限速主要用了令牌桶，用来平滑流量防止一瞬间被打垮，例如预约接口有整体系统限速每秒1000笔请求

## 4. 分布式环境下如何保证限速一致性？
通过使用redis+lua脚本

## 5. 知道哪些限速限流算法
常用的限流算法主要有： 固定窗口、滑动窗口、漏桶、令牌桶
它们的主要区别在于：限速精度、允许突发、实现复杂度和适用场景。

## 6. 什么是环形数组限速？
环形数组限流算滑动窗口算法的节省内存版本，它通过将滑动窗口划分为多个均匀的时间段，并存储在首尾相连的环形数组中，
随着时间推移不断覆盖旧数据并统计当前窗口内的请求总和，从而在极低的空间开销下实现滑动窗口限速

具体来说，是使用一个定长的数组代表滑动窗口，数组把这个窗口分为了很多个时间段，每个时间段内统计自己这段时间的请求总数
设置一个指针指向当前时刻位置，当窗口随时间向前滑动时，利用取模运算使指针随时间流动计算当前时刻位置，
指针移动时扫过的位置都认为是已过期数据，清空这些位置的计数，并在当前时刻位置视图增加一次计数
而整个数组中的计数的和就是当前最近一个时间窗口内的请求总数，以此来判断新请求是否会超速

## 6.1. 为什么要用环形数组限速，和记录时间戳的滑动窗口有什么区别？
一个是内存占用有明显区别
环形数组占用内存低的多，它不记录时间戳只计数，而且空间复杂度只取决于滑动窗口的颗粒度，这个颗粒度是个固定的值而且一般很小，我的项目中是10
而基于时间戳的滑动窗口存的是时间戳，并且空间复杂度会取决于消息的数量，在大流量时可能达到比较高的阈值，这个内存消耗是远大于环形数组的颗粒度的

再就是性能也有明显区别
环形数组不需要排序和移除过期数据，计算时按照取模运算公式进行清除和计数，非常高效，
而记录时间戳的滑动窗口则需要排序和清除窗口外数据，稍微复杂一些

最后环形数组的精度相对记录时间戳的滑动窗口是有些损失的，因为在相邻的两个最小时间段之间，还是类似固定窗口可能发生流量超速的，但是在颗粒度比较小时概率是很低的

# 日志篇

## 1. 你在项目中如何管理日志的
在具体操作中，我使用了slf4j管理日志，底层引擎是spring boot默认的Logback，具体使用的时候通过lombok的slf4注解简化操作。
在日志管理时，根据slf4j的规范，主要把日志分为这几类：首先是最常用的info级日志，把所有的重要业务流水信息都记录在info中；其次是error级别，用来记录程序中出错的信息，这种错误可能是数据不符合预期，
或者是不符合正常业务逻辑等等，需要人特别关注的信息，可能影响正常运行的。最后是fetal信息，用来记录一定会影响程序正常运行的严重错误。除此之外也可以用warn和debug级别，但是我在项目中不是很常用

# 并发篇

## 1. 你在项目中有遇到并发问题吗，如果多个用户预约同一个课程，是如何避免超额预约的
有，如果当多个用户同时预约一个课程时，如果处理不好，可能遇到同一课程被多个用户重复预约的情况。
在项目中我使用了基于redis的分布式锁解决了这个并发问题， 
具体来说，首先项目中使用了redis高级客户端redisson，使用了RLock作为核心的锁机制，当一个请求到来时，首先需要去redis获取请求对应的课程的锁，这里的锁粒度是课程级的，不会阻塞其他课程的预约；
如果无法拿到锁，并且超过了获取锁的等待时间，那么本次任务失败，返回服务器繁忙消息，这个锁的等待时间也是通过redisson配置的；
如果拿到锁，相当于在redis中设置了一个key-value，同时设置了锁的最大持有时间，如果超时则自动释放锁，
拿到锁后，开始进行业务逻辑的操作，在一个事务中更新mysql中课程的状态、咨询师的时刻表，然后删除redis缓存。在这个过程中如果有任何一方更新失败，则回滚所有操作
当状态变更完成后，释放锁，这个过程相当于是删除之前的key-value，或者当重入锁被释放时是相当于进行计数器count down
通过上面的操作，最终可以多线程、分布式的情况下，课程都会被正确预约，并且严格的持久化在数据库中，一旦发生任何服务器异常，可以从数据库中恢复全部正确的状态

## 2. 进阶版，你是怎么实现预约功能的，怎么避免超额预约的
在预约功能的实现上，我是在Redis中完成预扣减，然后通过MQ去异步落库的方式实现的
具体来说的话，当一个用户发起预约请求时，会去检查课程是否已被预约，如果没有被预约，则进行课程状态以及咨询师状态的更新，
然后这个检查和更新的操作我是放在了Lua脚本中，因为这样可以保证这个过程的原子性，防止并发安全问题，
然后使用redisson在redis中执行lua脚本，完成课程的预约，预约成功后向RabbitMQ中发送一条落库消息，
另外有一个落库消费者会去消费这条消息，完成数据落库，避免在下单时有IO操作，保持最终一致性

### 2.1 如果 Redis 扣减成功但 MQ 发送失败，如何保证一致性
当MQ发送失败时，我会在发送MQ的try-catch块中捕获到异常，然后立即在catch中执行redis的回滚操作lua脚本，把课程状态和咨询师状态的状态还原

### 2.2 落库太慢导致MQ消息堆积了怎么办
首先因为落库的IO操作是比较耗时的，所以我采用了批量落库的方式大大减少了落库次数，提升了落库模块的吞吐量
具体来说，是结合MQ的机制来完成的，首先还是关闭MQ消费者的自动确认，然后设置消费者的监听模式为Batch模式，每次批量从MQ中消费10条消息
然后操作数据库在一个事务中更新10条消息对应的所有数据，相当于可以降低10倍的IO操作，
如果落库成功，则对这10条消息返回处理成功的消费者confirm
如果落库失败，则对MQ返回NACK，拒绝掉所有消息，直接放入死信队列

### 2.3 如果一次落库中只有一条消息失败了，那其他消息也要跟着失败吗
如果批量事务失败，在catch块中再进行降级处理，降级为逐条消息落库，成功的给MQ发送ACK，失败的那一条发送NACK放入死信队列

### 2.4 你预约课程的这张表，介绍一下表的结构，有什么状态，预约是个什么流程
这个表主要存储了当前的课程id、对应的咨询师id、课程的状态，状态分为未预约和已预约
客户发起预约时，会先查询对应课程id的状态，如果是已预约就不能再预约，如果是未预约就去把这个课程的状态设置为已预约
同时也把对应的已预约课程表中添加数据，把咨询师表的对应咨询师时间段设置为忙碌

### 2.5 这个预约状态是个什么类型的数据，在redis里呢
是varchar类型，redis里是string

### 2.6 为什么用varchar，和char，text有什么区别
CHAR是定长的，
VARCHAR是变长的，需要多大空间就占用多大内存，灵活省空间，
TEXT是超大文本，数据存在行外能防撑大表体积，但查询效率最低
# 进阶篇
## 0. 你为什么进行jvm调优的，具体是什么问题，怎么发现的问题
这个首先说一下我遇到的问题吧，之前我们在对预约接口压测时，发现过了一段时间程序整体都很卡顿，所有接口响应都很慢，
然后我通过使用arthas，从dashboard观察到我们的Old gen老年代内存使用率有90%多，并且每分钟都在触发Full GC，
单次的Full GC的是时长也大幅增加，高达几百ms，所以怀疑是GC导致的CPU占用过多。

然后我使用Jmap，手动执行一次Full GC并统计GC后存活的对象，通过筛选出内存占用前20个，发现前几项主要是string，
同时有一个studentReportEntity对象占用很大，这是一个DAO层的数据库实体对象，所以这里非常怀疑是从数据库中加载了大量数据导致的了，

所以在代码中排查了一下，是因为我们在对预约接口压测时，产生了大量的预约记录，而我们有一个查看历史课程预约记录的接口，它全量的查询了最近一周的预约数据，
并且放在了一个arraylist中，并且后续它们还会进行序列化返回给前端，我使用的jackson进行json序列化时，底层还会再把它们转换成一个巨大的string，占用内存翻倍，
所以极大的耗费了内存。

由于对象特别大，直接被分配到了老年代，然后此时json序列化时间也很长，
在序列化完成并返回前端之前，GC根本回收不掉使用的这些内存，老年代很快被塞满，造成了GC时长的大幅增加，频率也大幅增加

不过预约记录平时通常不会特别多，所以一直也就没有问题。
### 0.1 后来怎么解决的
我用了Streaming JSON流式响应的方式解决了这个问题
首先在读数据库时，利用MyBatis的游标Cursor，让驱动程序以流式的方式而非全量的方式从数据库读取数
每当读取到数时，直接将读到的这条数据序列化，绕过Spring默认的内存全量序列化机制，操作HttpServletResponse写入网络流，
随后立即断开对这条数据的引用，通过这种方式，我们将接口的内存复杂度从 O(n) 降到了 O(1)。
对象在年轻代随生随灭，基本不进入老年代，彻底消除了由大对象堆积引发的 Full GC，同时也显著提升了前端的首字节响应时间


### 0.2 为什么单次GC的时长也会增加？
首先因为存活的对象本身就很多，导致可达性分析的耗时就会变长。
同时由于对象太多，JVM会把这几百MB的数据从年轻代复制到老年代，复制时非常消耗cpu
而且我们最开始使用的G1垃圾回收，当一个对象大小超过Region的一半时，会被直接分配到humongous region
此时G1通常需要寻找连续的Region去存放对象，如果没有足够的连续空间，会直接触发Full GC

### 0.3 你Jmap是用什么命令查的，说一下
jmap -histo:live 我的java进程id | head -n 20
histo就是生成堆中各对象的数量和占用空间，live是先触发一次GC再完成统计
然后通过管道的head -n过滤前20条数据

### 0.4 cursor是什么
cursor相当于是数据库结果集的一个指针。
如果不用cursor的话，查数据库时会把数据全量加载到java中；
当使用cursor时，不会直接把全部数据加载进来，而是先建立一个和数据库连接的通道
只有当代码里面调用cursor.next时,或者foreach时，它才会想数据库发送请求请求下一批数据
不过在连接MQSQL的时候，需要配置fetchSize为-2147483648才能做到逐条拉取

### 0.5 http响应怎么变成流式响应的
如果是spring框架帮我们响应，那么它不会进行流式响应，需要绕过框架的缓存机制，直接操作outputstream
http的分块传输编码transfer-encoding不再设置为报文内容的长度content-length，而需要设置为chunked，代表要进行流式响应
然后还需要设置content-type的类型，我用的json所以设置为了application/json

## 1. 用过arthas哪些命令
dashboard：用来实时观察各线程的一些状态、CPU的消耗。同时也可以观察到内存中各个部分的占用情况，GC的次数和耗时等
profiler：用来生成火焰图，观察cpu或者内存的占用情况


## 2. 怎么定位到是哪里引起GC的，怎么判断是对象创建太频繁，还是内存泄露引起的？
因为Full GC可能是由于频繁创建大对象导致内存波动剧烈，我使用了arthas的profiler，设置event alloc来生成内存分配的火焰图，
然后排查火焰图里面横向占用最宽的前几个点，根据对应业务包名去对应的代码钟排查。
如果是内存泄露的话，体现出来应该是内存缓慢增长回收不掉，可以通过heapdump导出堆文件，然后通过eclipse的MAT工具查看
首先看Leak Suspects报告获取全局概览，然后进入Dominator Tree定位大对象，
接着通过Path to GC Roots排除掉非强引用，找到该对象与GC Roots之间的引用链进行排查

## 3. 怎么更换垃圾回收器的
在java的启动参数中，设置 -XX:+UseZGC

## 4. 为什么要把G1换成ZGC？
因为ZGC的垃圾回收时间比G1快的多，尤其是对老年代的回收，G1需要几百ms，但是ZGC只需要10ms以内就可以完成回收，
因为虽然我在代码层面优化了对象创建，但是在压测时发现，当请求压力过大时还是会带来GC次数的提升，使用ZGC可以大幅降低STW带来的开销

# 了解篇

## 1. template是什么（redisTemplate rabbitmqTemplate）
是模板的意思，源于模板方法设计模式(template method pattern)，体现出一种模板化的设计思想
在Spring中，一个template就代表一种封装了复杂资源操作的固定流程（模式），只需要对模式填写必要数据就可以使用，不用在乎具体繁琐流程
例如redisTemplate，就是封装了redis客户端向redis服务器建立连接发送消息的过程，
rabbitmq也是封装了创建连接、通道、交换机队列的步骤，只需要传参填写就可以使用

## 2. 字符串序列化和json序列化有什么区别
字符串序列化（String Serialization）
将对象转换为字符串（通常调用对象的toString()方法）。
存储的是字符串，没有结构信息。
读取时，需要自己解析字符串来重建对象。

JSON序列化（JSON Serialization）
将对象转换为JSON格式的字符串（例如使用Jackson库）。
存储的是结构化的数据，包括字段名和值。
读取时，可以通过JSON反序列化直接重建对象，包括类型信息（如果使用带有类型信息的JSON序列化器）。
